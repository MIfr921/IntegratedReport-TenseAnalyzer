import streamlit as st
import pdfplumber
import re
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager
from collections import Counter
from janome.tokenizer import Tokenizer
from pykakasi import kakasi
import os, requests

# ===== ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆCloudå¯¾å¿œï¼‰ =====
FONT_URL = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/Japanese/NotoSansCJKjp-Regular.otf"
FONT_PATH = "NotoSansCJKjp-Regular.otf"
if not os.path.exists(FONT_PATH):
    r = requests.get(FONT_URL)
    with open(FONT_PATH, "wb") as f:
        f.write(r.content)
plt.rcParams['font.family'] = font_manager.FontProperties(fname=FONT_PATH).get_name()
plt.rcParams['axes.unicode_minus'] = False

# ===== Romajiå¤‰æ›å™¨ =====
kakasi_inst = kakasi()
kakasi_inst.setMode("H", "a")
kakasi_inst.setMode("K", "a")
kakasi_inst.setMode("J", "a")
converter = kakasi_inst.getConverter()
def to_roman(txt):
    """æ—¥æœ¬èªã‚’ãƒ­ãƒ¼ãƒå­—ã«å¤‰æ›"""
    if not isinstance(txt, str): return txt
    try: return converter.do(txt)
    except: return txt

# ===== Streamlitè¨­å®š =====
st.set_page_config(page_title="çµ±åˆå ±å‘Šæ›¸PDFèªå°¾ãƒ»æ™‚åˆ¶åˆ†æã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸ“„ çµ±åˆå ±å‘Šæ›¸PDFèªå°¾ãƒ»æ™‚åˆ¶åˆ†æã‚¢ãƒ—ãƒª")
st.write("ä¼æ¥­ã®çµ±åˆå ±å‘Šæ›¸PDFã‹ã‚‰æ–‡æœ«èªå°¾ã¨æ™‚åˆ¶ï¼ˆéå»å½¢ãƒ»ç¾åœ¨å½¢ï¼‰ã‚’åˆ†æã—ã€æ–‡ä½“å‚¾å‘ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚")

# ===== PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ =====
uploaded_file = st.file_uploader("åˆ†æã—ãŸã„çµ±åˆå ±å‘Šæ›¸PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["pdf"])

if uploaded_file is not None:
    with st.spinner("PDFã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        def extract_text_from_pdf(file):
            all_text = ""
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    text = page.extract_text()
                    if text:
                        all_text += text + "\n"
            return all_text

        text = extract_text_from_pdf(uploaded_file)
        st.success("âœ… PDFãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã—ãŸï¼")
        st.write("ğŸ“– æŠ½å‡ºã•ã‚ŒãŸå†’é ­éƒ¨åˆ†ï¼š")
        st.code(text[:500] + "..." if len(text) > 500 else text)

    # ===== æ–‡åˆ†å‰² =====
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
    sentences = [s.strip() for s in sentences if s.strip()]

    # ===== æ™‚åˆ¶åˆ†é¡ =====
    def get_tense(s):
        if re.search(r'(ãŸ|ã ã£ãŸ|ã¾ã—ãŸ|ã§ã—ãŸ)[^ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ ]*$', s):
            return "éå»å½¢"
        else:
            return "ç¾åœ¨ãƒ»æœªæ¥å½¢"

    df = pd.DataFrame([{"æ–‡": s, "åŒºåˆ†": get_tense(s)} for s in sentences])

    # ===== ğŸ¥§ æ™‚åˆ¶å‰²åˆï¼ˆã‚°ãƒ©ãƒ•ã®ã¿ãƒ­ãƒ¼ãƒå­—ï¼‰ =====
    st.subheader("ğŸ“ˆ æ™‚åˆ¶ã®å‰²åˆï¼ˆã‚°ãƒ©ãƒ•ï¼ãƒ­ãƒ¼ãƒå­—ï¼‰")
    tense_counts = df["åŒºåˆ†"].value_counts()

    # ã‚°ãƒ©ãƒ•ç”¨ã«ãƒ­ãƒ¼ãƒå­—åŒ–
    labels_romaji = [to_roman(label) for label in tense_counts.index]

    fig_ratio, ax_ratio = plt.subplots(figsize=(5,5))
    ax_ratio.pie(
        tense_counts,
        labels=labels_romaji,
        autopct="%1.1f%%",
        startangle=90,
        colors=["cornflowerblue", "orange"]
    )
    ax_ratio.axis("equal")
    ax_ratio.set_title("Kako-kei vs Genzai-Mirai-kei (Ratio)")
    st.pyplot(fig_ratio)

    # è¡¨ã¯æ—¥æœ¬èªã§è¡¨ç¤º
    st.dataframe(pd.DataFrame(tense_counts).rename(columns={"åŒºåˆ†":"æ–‡æ•°"}))

    # ===== æ–‡æœ«èªå°¾é›†è¨ˆ =====
    def extract_sentence_ending(s):
        m = re.search(r'(ã§ã‚ã‚‹|ã¨ãªã‚Šã¾ã™|ã«ãªã‚Šã¾ã™|ã„ãŸã—ã¾ã™|ã§ã—ãŸ|ã ã£ãŸ|ã¾ã™|ã¾ã—ãŸ|ã§ã™|ã )$', s)
        return m.group(1) if m else None

    endings = [extract_sentence_ending(s) for s in sentences if extract_sentence_ending(s)]
    ending_counts = Counter(endings)
    df_end = pd.DataFrame(ending_counts.items(), columns=["èªå°¾","å‡ºç¾å›æ•°"]).sort_values("å‡ºç¾å›æ•°",ascending=False)

    # ===== ğŸ“Š æ–‡æœ«èªå°¾é »åº¦ï¼ˆã‚°ãƒ©ãƒ•ï¼ãƒ­ãƒ¼ãƒå­—ï¼‰ =====
    st.subheader("ğŸ“Š æ–‡æœ«èªå°¾ã®å‡ºç¾é »åº¦ï¼ˆã‚°ãƒ©ãƒ•ï¼ãƒ­ãƒ¼ãƒå­—ï¼‰")
    st.dataframe(df_end, use_container_width=True)

    # ã‚°ãƒ©ãƒ•ç”¨ãƒ©ãƒ™ãƒ«ã‚’ãƒ­ãƒ¼ãƒå­—ã«å¤‰æ›
    labels_romaji = [to_roman(label) for label in df_end["èªå°¾"]]

    fig1, ax1 = plt.subplots(figsize=(6,4))
    ax1.barh(labels_romaji, df_end["å‡ºç¾å›æ•°"], color="steelblue")
    ax1.invert_yaxis()
    ax1.set_title("Sentence Endings Frequency (Romaji)", fontsize=13)
    ax1.set_xlabel("Count")
    st.pyplot(fig1)

    # ===== ğŸ•° æ™‚åˆ¶åˆ¥é »å‡ºèª =====
    st.subheader("ğŸ•° æ™‚åˆ¶åˆ¥é »å‡ºèªï¼ˆã‚°ãƒ©ãƒ•ï¼ãƒ­ãƒ¼ãƒå­—ï¼‰")
    tokenizer = Tokenizer()
    def extract_words(t):
        words=[]
        for tk in tokenizer.tokenize(t):
            if tk.part_of_speech.split(',')[0] in ["åè©","å‹•è©","å½¢å®¹è©"]:
                words.append(tk.base_form)
        return words

    word_freq={}
    for label,grp in df.groupby("åŒºåˆ†"):
        ws=[]
        for s in grp["æ–‡"]: ws.extend(extract_words(s))
        word_freq[label]=Counter(ws).most_common(20)

    col1,col2=st.columns(2)
    with col1:
        st.markdown("#### ğŸ”µ éå»å½¢")
        past_df=pd.DataFrame(word_freq.get("éå»å½¢",[]),columns=["å˜èª","å‡ºç¾å›æ•°"])
        st.dataframe(past_df)
        if not past_df.empty:
            fig2,ax2=plt.subplots(figsize=(6,4))
            # ã‚°ãƒ©ãƒ•ã®ãƒ©ãƒ™ãƒ«ã ã‘ãƒ­ãƒ¼ãƒå­—åŒ–
            ax2.barh([to_roman(w) for w in past_df["å˜èª"]], past_df["å‡ºç¾å›æ•°"], color="cornflowerblue")
            ax2.invert_yaxis(); ax2.set_title("Kako-kei: Frequent Words (Romaji)")
            st.pyplot(fig2)
    with col2:
        st.markdown("#### ğŸŸ  ç¾åœ¨ãƒ»æœªæ¥å½¢")
        fut_df=pd.DataFrame(word_freq.get("ç¾åœ¨ãƒ»æœªæ¥å½¢",[]),columns=["å˜èª","å‡ºç¾å›æ•°"])
        st.dataframe(fut_df)
        if not fut_df.empty:
            fig3,ax3=plt.subplots(figsize=(6,4))
            ax3.barh([to_roman(w) for w in fut_df["å˜èª"]], fut_df["å‡ºç¾å›æ•°"], color="orange")
            ax3.invert_yaxis(); ax3.set_title("Genzai-Mirai-kei: Frequent Words (Romaji)")
            st.pyplot(fig3)

    # ===== CSVå‡ºåŠ›ï¼ˆæ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ï¼‰ =====
    csv = df_end.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        "ğŸ“¥ æ–‡æœ«èªå°¾é›†è¨ˆçµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ—¥æœ¬èªï¼‰",
        data=csv,
        file_name="ending_counts_japanese.csv",
        mime="text/csv"
    )

else:
    st.info("ğŸ‘† ä¸Šã®ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰çµ±åˆå ±å‘Šæ›¸PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
