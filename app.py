import streamlit as st
import pdfplumber
import re
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager
from collections import Counter
from janome.tokenizer import Tokenizer
from pykakasi import kakasi
import os, requests
from scipy.stats import chi2_contingency, fisher_exact

# ===== ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆCloudå¯¾å¿œï¼‰ =====
FONT_URL = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/Japanese/NotoSansCJKjp-Regular.otf"
FONT_PATH = "NotoSansCJKjp-Regular.otf"
if not os.path.exists(FONT_PATH):
    r = requests.get(FONT_URL)
    with open(FONT_PATH, "wb") as f:
        f.write(r.content)
plt.rcParams['font.family'] = font_manager.FontProperties(fname=FONT_PATH).get_name()
plt.rcParams['axes.unicode_minus'] = False

# ===== Romajiå¤‰æ›å™¨ =====
kakasi_inst = kakasi()
kakasi_inst.setMode("H", "a")
kakasi_inst.setMode("K", "a")
kakasi_inst.setMode("J", "a")
converter = kakasi_inst.getConverter()
def to_roman(txt):
    if not isinstance(txt, str): return txt
    try: return converter.do(txt)
    except: return txt

# ===== Streamlitè¨­å®š =====
st.set_page_config(page_title="çµ±åˆå ±å‘Šæ›¸PDFèªå°¾ãƒ»æ™‚åˆ¶åˆ†æã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸ“„ çµ±åˆå ±å‘Šæ›¸PDFèªå°¾ãƒ»æ™‚åˆ¶åˆ†æã‚¢ãƒ—ãƒª")
st.write("ä¼æ¥­ã®çµ±åˆå ±å‘Šæ›¸PDFã‹ã‚‰æ–‡æœ«èªå°¾ãƒ»æ™‚åˆ¶ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‚¾å‘ã‚’åˆ†æã—ã¾ã™ã€‚")

# ===== PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ =====
uploaded_file = st.file_uploader("åˆ†æã—ãŸã„çµ±åˆå ±å‘Šæ›¸PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["pdf"])

if uploaded_file is not None:
    with st.spinner("PDFã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        def extract_text_from_pdf(file):
            all_text = ""
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    text = page.extract_text()
                    if text:
                        all_text += text + "\n"
            return all_text

        text = extract_text_from_pdf(uploaded_file)
        st.success("âœ… PDFãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã—ãŸï¼")
        st.write("ğŸ“– æŠ½å‡ºã•ã‚ŒãŸå†’é ­éƒ¨åˆ†ï¼š")
        st.code(text[:500] + "..." if len(text) > 500 else text)

    # ===== æ–‡åˆ†å‰² =====
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
    sentences = [s.strip() for s in sentences if s.strip()]

    # ===== æ™‚åˆ¶åˆ†é¡ =====
    def get_tense(s):
        if re.search(r'(ãŸ|ã ã£ãŸ|ã¾ã—ãŸ|ã§ã—ãŸ)[^ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ ]*$', s):
            return "éå»å½¢"
        else:
            return "ç¾åœ¨ãƒ»æœªæ¥å½¢"

    df = pd.DataFrame([{"æ–‡": s, "åŒºåˆ†": get_tense(s)} for s in sentences])

    # ===== ğŸ¥§ æ™‚åˆ¶ã®å‰²åˆï¼ˆã‚°ãƒ©ãƒ•ã¯ãƒ­ãƒ¼ãƒå­—ï¼‰ =====
    st.subheader("ğŸ“ˆ æ™‚åˆ¶ã®å‰²åˆï¼ˆã‚°ãƒ©ãƒ•ï¼ãƒ­ãƒ¼ãƒå­—ï¼‰")
    tense_counts = df["åŒºåˆ†"].value_counts()
    labels_romaji = [to_roman(label) for label in tense_counts.index]
    fig_ratio, ax_ratio = plt.subplots(figsize=(5,5))
    ax_ratio.pie(
        tense_counts,
        labels=labels_romaji,
        autopct="%1.1f%%",
        startangle=90,
        colors=["cornflowerblue", "orange"]
    )
    ax_ratio.axis("equal")
    ax_ratio.set_title("Kako-kei vs Genzai-Mirai-kei (Ratio)")
    st.pyplot(fig_ratio)
    st.dataframe(pd.DataFrame(tense_counts).rename(columns={"åŒºåˆ†":"æ–‡æ•°"}))

    # ===== æ–‡æœ«èªå°¾æŠ½å‡º =====
    def extract_sentence_ending(s):
        s = re.sub(r'[ã€‚ã€\s]+$', '', s)
        target = s[-10:]
        m = re.search(r'(ã§ã—ãŸ|ã ã£ãŸ|ã¾ã™|ã¾ã—ãŸ|ã§ã™|ã™ã‚‹|ã—ãŸ|ãªã‚‹|ã§ã‚ã‚‹)$', target)
        return m.group(1) if m else None

    endings = [extract_sentence_ending(s) for s in sentences if extract_sentence_ending(s)]
    ending_counts = Counter(endings)
    df_end = pd.DataFrame(ending_counts.items(), columns=["èªå°¾","å‡ºç¾å›æ•°"]).sort_values("å‡ºç¾å›æ•°",ascending=False)

    st.subheader("ğŸ“Š æ–‡æœ«èªå°¾ã®å‡ºç¾é »åº¦ï¼ˆã‚°ãƒ©ãƒ•ï¼ãƒ­ãƒ¼ãƒå­—ï¼‰")
    st.dataframe(df_end, use_container_width=True)
    fig1, ax1 = plt.subplots(figsize=(6,4))
    ax1.barh([to_roman(w) for w in df_end["èªå°¾"]], df_end["å‡ºç¾å›æ•°"], color="steelblue")
    ax1.invert_yaxis()
    ax1.set_title("Sentence Endings Frequency (Romaji)", fontsize=13)
    ax1.set_xlabel("Count")
    st.pyplot(fig1)

    # ===== ğŸ“ ç‰¹å®šèªã®å‡ºç¾é »åº¦ã¨çµ±è¨ˆæ¯”è¼ƒ =====
    st.subheader("ğŸ“ ç‰¹å®šèªã®å‡ºç¾é »åº¦ãƒ»å‰²åˆãƒ»çµ±è¨ˆæ¤œå®š")
    user_input = st.text_input("ã‚«ã‚¦ãƒ³ãƒˆã—ãŸã„èªã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šæˆé•·,æ–¹é‡,æœªæ¥ï¼‰")

    if user_input:
        keywords = [w.strip() for w in user_input.split(",") if w.strip()]
        results = []
        total_past = len(df[df["åŒºåˆ†"]=="éå»å½¢"])
        total_future = len(df[df["åŒºåˆ†"]=="ç¾åœ¨ãƒ»æœªæ¥å½¢"])

        for word in keywords:
            past_contains = df[df["åŒºåˆ†"]=="éå»å½¢"]["æ–‡"].apply(lambda x: word in x).sum()
            future_contains = df[df["åŒºåˆ†"]=="ç¾åœ¨ãƒ»æœªæ¥å½¢"]["æ–‡"].apply(lambda x: word in x).sum()

            # å‰²åˆ
            past_ratio = past_contains / total_past * 100 if total_past else 0
            future_ratio = future_contains / total_future * 100 if total_future else 0

            # 2Ã—2è¡¨
            table = [[past_contains, total_past - past_contains],
                     [future_contains, total_future - future_contains]]

            try:
                chi2, p, dof, ex = chi2_contingency(table)
            except ValueError:
                # 0ãŒã‚ã‚‹å ´åˆã¯Fisher
                _, p = fisher_exact(table)

            results.append({
                "èª": word,
                "éå»å½¢_æ–‡æ•°": past_contains,
                "ç¾åœ¨ãƒ»æœªæ¥å½¢_æ–‡æ•°": future_contains,
                "éå»å½¢_å‰²åˆ(%)": round(past_ratio, 2),
                "ç¾åœ¨ãƒ»æœªæ¥å½¢_å‰²åˆ(%)": round(future_ratio, 2),
                "på€¤": round(p, 4)
            })

        df_stats = pd.DataFrame(results).sort_values("på€¤")
        st.dataframe(df_stats, use_container_width=True)

        # --- ã‚°ãƒ©ãƒ•åŒ–ï¼ˆãƒ­ãƒ¼ãƒå­—ãƒ©ãƒ™ãƒ«ï¼‰ ---
        fig_kw, ax_kw = plt.subplots(figsize=(6, 4))
        ax_kw.barh([to_roman(w) for w in df_stats["èª"]], df_stats["éå»å½¢_æ–‡æ•°"], color="cornflowerblue", label="Past")
        ax_kw.barh([to_roman(w) for w in df_stats["èª"]], df_stats["ç¾åœ¨ãƒ»æœªæ¥å½¢_æ–‡æ•°"], color="orange", left=df_stats["éå»å½¢_æ–‡æ•°"], label="Present/Future")
        ax_kw.invert_yaxis()
        ax_kw.set_title("Keyword Count by Tense (Romaji)", fontsize=13)
        ax_kw.set_xlabel("Sentence Count")
        ax_kw.legend()
        st.pyplot(fig_kw)

    # ===== CSVå‡ºåŠ›ï¼ˆæ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ï¼‰ =====
    csv = df_end.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        "ğŸ“¥ æ–‡æœ«èªå°¾é›†è¨ˆçµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ—¥æœ¬èªï¼‰",
        data=csv,
        file_name="ending_counts_japanese.csv",
        mime="text/csv"
    )

else:
    st.info("ğŸ‘† ä¸Šã®ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰çµ±åˆå ±å‘Šæ›¸PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
